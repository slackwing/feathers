#!/usr/bin/env python3
"""
Utility script for Kaprekar CSV output files.
- Clean mode: Delete empty or header-only CSV files
- Matrix mode: Show ASCII grid of available base-digit combinations
"""

import argparse
import os
import sys
import re
from pathlib import Path
from collections import defaultdict


def is_empty_or_header_only(csv_path):
    """
    Check if a CSV file is empty or contains only headers.

    Args:
        csv_path: Path to the CSV file

    Returns:
        tuple: (should_delete, reason) where reason is a string explaining why
    """
    # Check file size
    if csv_path.stat().st_size == 0:
        return (True, "0 bytes")

    # Check if only headers (1 or 2 lines - some CSVs have blank line after header)
    try:
        with open(csv_path, 'r') as f:
            lines = f.readlines()
            # Only headers if 1 line, or 2 lines where second is empty
            if len(lines) == 1:
                return (True, "header only")
            elif len(lines) == 2 and lines[1].strip() == '':
                return (True, "header only")
            else:
                return (False, None)
    except Exception as e:
        print(f"Warning: Could not read {csv_path}: {e}", file=sys.stderr)
        return (False, None)


def find_csv_files(data_dir):
    """
    Find all CSV files in the data directory (including subdirectories).

    Args:
        data_dir: Path to the data directory

    Returns:
        list: List of Path objects for CSV files
    """
    data_path = Path(data_dir)
    if not data_path.exists():
        print(f"Error: Data directory '{data_dir}' does not exist", file=sys.stderr)
        sys.exit(1)

    if not data_path.is_dir():
        print(f"Error: '{data_dir}' is not a directory", file=sys.stderr)
        sys.exit(1)

    # Find all CSV files recursively
    csv_files = list(data_path.rglob('*.csv'))
    return csv_files


def parse_csv_filename(csv_path):
    """
    Parse CSV filename to extract base and digit ranges.
    Expected format: kaprekar_summary_baseX-Y_digitsA-B.csv or kaprekar_fp_baseX-Y_digitsA-B.csv

    Args:
        csv_path: Path to the CSV file

    Returns:
        tuple: (base_min, base_max, digits_min, digits_max) or None if parsing fails
    """
    filename = csv_path.name
    # Match pattern: kaprekar_(summary|fp)_baseX-Y_digitsA-B.csv
    pattern = r'kaprekar_(?:summary|fp)_base(\d+)-(\d+)_digits(\d+)-(\d+)\.csv'
    match = re.match(pattern, filename)

    if match:
        base_min, base_max, digits_min, digits_max = map(int, match.groups())
        return (base_min, base_max, digits_min, digits_max)

    return None


def do_clean(data_dir, dry_run):
    """
    Clean mode: Delete empty or header-only CSV files.

    Args:
        data_dir: Path to the data directory
        dry_run: If True, show what would be deleted without deleting
    """
    # Find all CSV files
    csv_files = find_csv_files(data_dir)

    if not csv_files:
        print(f"No CSV files found in '{data_dir}'")
        return

    print(f"Found {len(csv_files)} CSV file(s) in '{data_dir}'")
    print()

    # Check each file and collect deletions
    to_delete = []
    for csv_path in csv_files:
        should_delete, reason = is_empty_or_header_only(csv_path)
        if should_delete:
            to_delete.append((csv_path, reason))

    # Report findings
    if not to_delete:
        print("No empty or header-only CSV files found. Nothing to delete.")
        return

    print(f"Found {len(to_delete)} file(s) to delete:")
    print()

    for csv_path, reason in to_delete:
        rel_path = csv_path.relative_to(data_dir)
        print(f"  {rel_path} ({reason})")

    print()

    # Delete files (or dry-run)
    if dry_run:
        print("Dry-run mode: No files were deleted.")
    else:
        for csv_path, reason in to_delete:
            try:
                csv_path.unlink()
            except Exception as e:
                print(f"Error deleting {csv_path}: {e}", file=sys.stderr)

        print(f"Deleted {len(to_delete)} file(s).")


def do_matrix(data_dir):
    """
    Matrix mode: Show ASCII grid of available base-digit combinations.
    Shows ★ for true Kaprekar (1 fixed point, 0 cycles), ✓ for other results.

    Args:
        data_dir: Path to the data directory
    """
    # Find all CSV files
    csv_files = find_csv_files(data_dir)

    if not csv_files:
        print(f"No CSV files found in '{data_dir}'")
        return

    # Parse filenames and collect base-digit combinations
    # Use dict to track (base, digit) -> is_true_kaprekar
    combinations = {}

    for csv_path in csv_files:
        # Only process summary CSVs (they have the num_cycles and fixed_points data)
        if 'kaprekar_summary' not in csv_path.name:
            continue

        parsed = parse_csv_filename(csv_path)
        if not parsed:
            continue

        base_min, base_max, digits_min, digits_max = parsed

        # Try to read the summary CSV to check for true Kaprekar
        try:
            import csv
            with open(csv_path, 'r') as f:
                reader = csv.DictReader(f)
                for row in reader:
                    base = int(row['base'])
                    digits = int(row['digits'])
                    num_cycles = int(row['num_cycles'])
                    fixed_points = int(row['fixed_points'])

                    # True Kaprekar: exactly 1 fixed point, 0 cycles
                    is_true_kaprekar = (num_cycles == 0 and fixed_points == 1)
                    combinations[(base, digits)] = is_true_kaprekar
        except Exception as e:
            # If we can't read the file, just mark combinations as present (not true Kaprekar)
            for base in range(base_min, base_max + 1):
                for digits in range(digits_min, digits_max + 1):
                    if (base, digits) not in combinations:
                        combinations[(base, digits)] = False

    if not combinations:
        print("No valid Kaprekar CSV files found (expected format: kaprekar_*_baseX-Y_digitsA-B.csv)")
        return

    # Find ranges for the matrix
    all_bases = [b for b, d in combinations.keys()]
    all_digits = [d for b, d in combinations.keys()]

    min_base = min(all_bases)
    max_base = max(all_bases)
    min_digits = min(all_digits)
    max_digits = max(all_digits)

    # Count true Kaprekar vs other results
    true_kaprekar_count = sum(1 for is_tk in combinations.values() if is_tk)

    print(f"Data coverage matrix (base {min_base}-{max_base}, digits {min_digits}-{max_digits}):")
    print(f"Found {len(combinations)} base-digit combination(s), {true_kaprekar_count} true Kaprekar (★)")
    print()

    # Print header (digits across top)
    print("      ", end="")
    for digits in range(min_digits, max_digits + 1):
        print(f"{digits:3d}", end="")
    print()
    print("      " + "-" * (3 * (max_digits - min_digits + 1)))

    # Print matrix rows (base on y-axis, reversed so higher bases are higher)
    for base in range(max_base, min_base - 1, -1):
        print(f"{base:3d} | ", end="")
        for digits in range(min_digits, max_digits + 1):
            if (base, digits) in combinations:
                if combinations[(base, digits)]:
                    print("  ★", end="")  # True Kaprekar
                else:
                    print("  ·", end="")  # Other result
            else:
                print("   ", end="")
        print()


def main():
    parser = argparse.ArgumentParser(
        description='Utility for Kaprekar CSV output files'
    )
    parser.add_argument(
        '--data-dir',
        type=str,
        required=True,
        help='Directory containing CSV files'
    )

    # Mode selection (mutually exclusive)
    mode_group = parser.add_mutually_exclusive_group(required=True)
    mode_group.add_argument(
        '--clean',
        action='store_true',
        help='Delete empty or header-only CSV files'
    )
    mode_group.add_argument(
        '--matrix',
        action='store_true',
        help='Show ASCII grid of available base-digit combinations'
    )

    # Clean mode options
    parser.add_argument(
        '--dry-run',
        action='store_true',
        help='(Clean mode only) Show what would be deleted without actually deleting'
    )

    args = parser.parse_args()

    # Execute the appropriate mode
    if args.clean:
        do_clean(args.data_dir, args.dry_run)
    elif args.matrix:
        do_matrix(args.data_dir)


if __name__ == '__main__':
    main()
